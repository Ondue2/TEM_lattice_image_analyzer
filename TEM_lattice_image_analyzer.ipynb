{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db97124f-ec59-4213-b4f6-1ad4c6f52ba1",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a02c6aa-d94a-4314-a774-2577c3473eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import tools_v2 as tools\n",
    "import Gaussian_functions_v2 as gf\n",
    "import loss_functions as lf\n",
    "\n",
    "import ipywidgets as widgets\n",
    "\n",
    "base_dir = \"dir1/dir2/\"      # Data will be saved here\n",
    "sample = \"sample\"            # sample name, which will be included in file names to be saved\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5753a68d-9bdb-40e5-acec-bcf053ab95b3",
   "metadata": {},
   "source": [
    "## Import TEM images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f227ba1a-de12-409f-abb2-402f90cec572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperspy.api as hs       # modules needed to import TEM images in a form of ndarray.\n",
    "\n",
    "file1 = hs.load(base_dir + \"file_name1.tif\").data \n",
    "file2 = hs.load(base_dir + \"file_name2.dm4\").data \n",
    "\n",
    "TEM_array = file1              # TEM_array should receive the 2d array form of the TEM image\n",
    "\n",
    "plt.imshow(TEM_array, cmap = \"grey\")              \n",
    "print(\"image shape:\", TEM_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81668625-4e1c-472b-8d43-895ad0165a6a",
   "metadata": {},
   "source": [
    "## Image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0907ad6-e3f9-48c0-b22c-c1fcb5651dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotate_angle = 0.0   # counter-clockwise rotation in deg\n",
    "\n",
    "# Boundary information for cropping \n",
    "\n",
    "x = 100                            # x coordinate of upper left vertex of the cropped image in pixels\n",
    "y = 100                            # y coordinate of upper left vertex of the cropped image in pixels\n",
    "width = 2000                       # width of the cropped image in pixels\n",
    "height = 2000                      # height of the cropped image in pixels\n",
    "\n",
    "line_width = 2       # line width for a box showing the boundary for the croped image\n",
    "\n",
    "normalized_maximum_intensity = 10          # processed image will have this maximum intensity\n",
    "low_intensity_threshold = 0.1              \n",
    "# intensity less than the (threshold* maximum intensity) will be cut off for noise suppression\n",
    "\n",
    "im_analyzed, tf_im_analyzed = tools.image_preprocess(TEM_array, rotate_angle, \n",
    "                                                     normalized_maximum_intensity, low_intensity_threshold, \n", 
    "                                                     x, y, width, height, line_width)\n",
    "im_shape = im_analyzed.shape\n",
    "\n",
    "# im_analyzed is 2-d numpy array of the processed image, and tf_im_analyzed is the tensor version of that.\n",
    "\n",
    "im_analyzed_file_name = \"im_analyzed\"\n",
    "np.save(base_dir + im_analyzed_file_name + \"_\" + sample, im_analyzed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc0bf10-1f69-4540-b4a4-5405813ff399",
   "metadata": {},
   "source": [
    "## Lattice parameter setting and check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af5805a-b2d8-498f-b6d2-6adc6a0a0bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_pix = 0.1             # length of one pixel in angstrom\n",
    "\n",
    "x_lattice = 5.0                     # lateral lattice constant in angstrom\n",
    "y_lattice = 5.0                     # vertical lattice constant in angstrom\n",
    "x_off = 10                      # x coordinate of the upper left lattice point in pixel\n",
    "y_off = 10                      # y coordinate of the upper left lattice point in pixel\n",
    "sliding = [0,     #1\n",
    "           0,     #2\n",
    "           0,     #3\n",
    "           0]     #4    \n",
    "# Relative x offsets of the lattice points from the second to last rows with respect to that of the first row\n",
    "\n",
    "row = 5                        # number of rows to be analyzed\n",
    "col = 10                       # number of columns to be analyzed\n",
    "\n",
    "x_look = 0                     # upper left x coordinate of focusing box in the unit cell in pixel\n",
    "y_look = 0                     # upper left y coordinate of focusing box in the unit cell in pixel\n",
    "width_look = 50                # width of focusing box in the unit cell\n",
    "height_look = 40               # height of focusing box in the unit cell\n",
    "\n",
    "unit_cell_image, tf_unit_cell_image, lattices, lattice_num, TEM_image_with_grid = \\\n",
    "tools.lattice_parameter_tunning(x_lattice, y_lattice, x_off, y_off, len_pix, row, col, sliding, im_analyzed,\n",
    "                             x_look, y_look, width_look, height_look)\n",
    "\n",
    "# unit_cell_image is a 2-dimensional numpy array of unit cell image.\n",
    "# tf_unit_cell_image is the tensor version of unit_cell_image\n",
    "\n",
    "\n",
    "lattice_num_file_name = \"lattice_num\"\n",
    "unitcell_file_name = \"unitcell\"\n",
    "x_lattice_file_name = \"x_lattice\"\n",
    "y_lattice_file_name = \"y_lattice\"\n",
    "len_pix_file_name = \"len_pix\"\n",
    "\n",
    "np.save(base_dir + lattice_num_file_name + \"_\" + sample, lattice_num)\n",
    "np.save(base_dir + unitcell_file_name + \"_\" + sample, unit_cell_image)\n",
    "np.save(base_dir + x_lattice_file_name + \"_\" + sample, x_lattice)\n",
    "np.save(base_dir + y_lattice_file_name + \"_\" + sample, y_lattice)\n",
    "np.save(base_dir + len_pix_file_name + \"_\" + sample, len_pix)\n",
    "\n",
    "TEM_image_with_grid.savefig(base_dir + f\"TEM_image_with_grid_{sample}.png\", dpi = 300, bbox_inches = 'tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46533713-caa0-447c-ac85-48686133fd68",
   "metadata": {},
   "source": [
    "## Unit cell investigator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484c5e39-aaaa-4b7f-aad7-427ac3f55821",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.unit_cell_investigator(unit_cell_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a413f1a-8d30-4806-8eb0-9d742d280ed2",
   "metadata": {},
   "source": [
    "## Atomic positions in unit cell setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98720764-a087-4e99-bd3f-720242454336",
   "metadata": {},
   "outputs": [],
   "source": [
    "Atom_positions_dic = {\"Atom 1\" : [[0.1, 0.1], [0.9, 0.9],], \n",
    "                      \"Atom 2\": [[0.5,0.5],],\n",
    "                      \"Atom 3\": [[0.4, 0.2], [0.6, 0.2],\n",
    "                                [0.4, 0.8], [0.6, 0.8],]}\n",
    "\n",
    "marker_size = 50\n",
    "\n",
    "posit_pix, atom_num_list, atom_num_in_unit_cell = tools.atom_positions_iu_gen_check(Atom_positions_dic, \n",
    "                                                                                    unit_cell_image, \n", 
    "                                                                                    x_lattice, \n",
    "                                                                                    y_lattice, \n",
    "                                                                                    len_pix,\n",
    "                                                                                    marker_size)\n",
    "\n",
    "atom_name_list = list(Atom_positions_dic.keys())\n",
    "\n",
    "atom_num_list_file_name = \"atom_num_list\"\n",
    "atom_name_list_file_name = \"atom_name_list\"\n",
    "np.save(base_dir + atom_num_list_file_name + \"_\" + sample, atom_num_list)\n",
    "np.save(base_dir + atom_name_list_file_name + \"_\" + sample, atom_name_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd9cd4d-1081-4c58-bd72-4420dbc4a1f1",
   "metadata": {},
   "source": [
    "## Initialize atomic positions with peak finder unit cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ac5136-126f-4cd6-8000-9f2466dbecc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each element is for each atom in the keywords of Atom_positions_dic.\n",
    "\n",
    "peak_finder_pad_size_list = [5, 5, 5]    \n",
    "\n",
    "marker_size = 50\n",
    "\n",
    "first_posit_pix_file_name = \"first_posit_pix\"\n",
    "\n",
    "posit_pix_peaks = tools.unit_cell_peak_finder(peak_finder_pad_size_list, \n",
    "                          atom_num_list, posit_pix, unit_cell_image, marker_size, atom_name_list)\n",
    "\n",
    "# posit_pix_peaks is correccted posit_pix by peak_finders\n",
    "\n",
    "np.save(base_dir + first_posit_pix_file_name + \"_\" + sample, posit_pix_peaks[0][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892ca0ee-6c88-440b-b431-985fc6871184",
   "metadata": {},
   "source": [
    "## Parameter setting for unit cell optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24b7a8e-f85a-4748-83fe-71d7f8a63944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each element is for each atom in the keywords of Atom_positions_dic.\n",
    "\n",
    "pad_size_list = [20, 20, 20]                               \n",
    "amplitude = [5.0, 5.0, 5.0]       # Initial guess of Gaussian amplitude \n",
    "sig_x = [5.0, 5.0, 5.0]           # Initial guess of Gaussian width in x direction in pixel\n",
    "sig_y = [5.0, 5.0, 5.0]           # Initial guess of Gaussian width in y direction in pixel \n",
    "theta = [0.0, 0.0, 0.0]           # Initial guess of roataion angle or Gaussian function in deg\n",
    "\n",
    "\n",
    "tfv_dposit = tf.Variable(tf.zeros((2, atom_num_in_unit_cell), dtype = tf.float32))              \n",
    "# modulation of atomic positions in the unit cell to be optimized  \n",
    "\n",
    "tfv_unit_cell_params = tf.Variable(tf.stack([amplitude, sig_x, sig_y, theta], axis = 0))        \n",
    "# Gaussian parameters of the unit cell to be optimized\n",
    "\n",
    "loss_array = [] \n",
    "\n",
    "pad_size_list_file_name = \"pad_size_list\"\n",
    "np.save(base_dir + pad_size_list_file_name + \"_\" + sample, pad_size_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7289587-88c5-4ac9-8395-48a33648e680",
   "metadata": {},
   "source": [
    "## Unit cell optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a11fa64-4196-4c33-8ef0-26512b16ae47",
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_positions_in_unit_cell_file_name = \"atom_positions_in_unit_cell\"       # Optimized atomic positions in unit cell to save (.npy)\n",
    "unit_cell_params_file_name = \"unit_cell_params\"                             # Optimized unit cell Gaussian paramters to save (.npy)\n",
    "\n",
    "n_iter = 300                 # number of interation of gradient decent\n",
    "\n",
    "lr_pos = 1e-2                # learning rate of the positional modulation update (tfv.deposit)\n",
    "lr_param = 1e-2              # learning rate of the Gaussian parameters update (tfv_unit_cell_params)\n",
    "\n",
    "print_num = 10               # loss will be printed out each print_num'th iteration\n",
    "\n",
    "Fixed_params = [[1, 1], [2, 2]]     # [params_index, atom_index]\n",
    "\n",
    "Max_position_modul = 0.5     # Maximum amount of positional modulations in pixel\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "\n",
    "tfv_dposit.assign(tf.clip_by_value(tfv_dposit, -Max_position_modul, Max_position_modul))\n",
    "\n",
    "pos_optimizer = tf.optimizers.Adam(learning_rate=lr_pos) \n",
    "param_optimizer = tf.optimizers.Adam(learning_rate=lr_param)\n",
    "variables = [tfv_dposit, tfv_unit_cell_params]\n",
    "\n",
    "for i in range(n_iter):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        simulated_image = gf.Gaussian_unitcell(posit_pix_peaks, tfv_dposit, tfv_unit_cell_params, \n",
    "                                               atom_num_list, pad_size_list, unit_cell_image.shape)\n",
    "\n",
    "        loss = lf.compute_loss_tf(tf_unit_cell_image, simulated_image)\n",
    "        loss_array.append(loss)\n",
    "  \n",
    "        grads = tape.gradient(loss, variables) \n",
    "\n",
    "        if len(Fixed_params) != 0:\n",
    "            grads[1] = tf.tensor_scatter_nd_update(grads[1], Fixed_params, \n",
    "                                                   tf.zeros((len(Fixed_params),)))\n",
    "            \n",
    "        pos_optimizer.apply_gradients([(grads[0], tfv_dposit)])\n",
    "        param_optimizer.apply_gradients([(grads[1], tfv_unit_cell_params)])\n",
    "\n",
    "        np.save(base_dir + atom_positions_in_unit_cell_file_name + \"_\" + sample, np.array(tfv_dposit))\n",
    "        np.save(base_dir + unit_cell_params_file_name + \"_\" + sample, np.array(tfv_unit_cell_params))  \n",
    "\n",
    "        if i % print_num == 0:\n",
    "            \n",
    "            print(f'{i}, current_loss: {loss}')\n",
    "     \n",
    "plt.plot(np.arange(len(loss_array)), loss_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0667fac-2e93-4535-b037-b8d866fc9c88",
   "metadata": {},
   "source": [
    "## Unit cell optimization result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eaffe8-9a57-4789-9971-ecb459bc9f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_positions_in_unit_cell_file_name = \"atom_positions_in_unit_cell\"       # Optimized atomic poistions in unit cell to load (.npy)\n",
    "unit_cell_params_file_name = \"unit_cell_params\"                             # Optimized unit cell Gaussian paramters to load (.npy)\n",
    "\n",
    "unit_cell_information_file_name = \"unit_cell_information\"              # Unit cell information to save (.txt)\n",
    "\n",
    "marker_size = 50\n",
    "\n",
    "(tfv_dposit, tfv_unit_cell_params, atom_resolved_positions, atom_resolved_params, \n",
    " unit_cell_simul_image, Unit_cell_markers, Unit_cell_comparison) = \\\n",
    "tools.unit_cell_optimization_result(posit_pix, atom_num_list, pad_size_list, unit_cell_image, unit_cell_image.shape, \n",
    "                                    atom_positions_in_unit_cell_file_name, unit_cell_params_file_name, sample, \n",
    "                                    atom_name_list, unit_cell_information_file_name, marker_size,\n",
    "                                    base_dir)\n",
    "\n",
    "Unit_cell_markers.savefig(base_dir + f\"Unit_cell_markers_{sample}.png\", dpi = 300, bbox_inches = 'tight')\n",
    "Unit_cell_comparison.savefig(base_dir + f\"Unit_cell_comparison_{sample}.png\", dpi = 300, bbox_inches = 'tight')\n",
    "\n",
    "np.savetxt(base_dir + f\"Unit_cell_ndarray_{sample}.txt\", unit_cell_image)\n",
    "np.savetxt(base_dir + f\"Simulated_unit_cell_ndarray_{sample}.txt\", unit_cell_simul_image)\n",
    "\n",
    "for atom in range(len(atom_num_list)):\n",
    "\n",
    "    np.savetxt(base_dir + f\"{atom_name_list[atom]}_x_unit_cell_{sample}.txt\", atom_resolved_positions[atom][0, :])\n",
    "    np.savetxt(base_dir + f\"{atom_name_list[atom]}_y_unit_cell_{sample}.txt\", atom_resolved_positions[atom][1, :])\n",
    "    np.savetxt(base_dir + f\"{atom_name_list[atom]}_A_unit_cell_{sample}.txt\", atom_resolved_params[atom][0, :])\n",
    "    np.savetxt(base_dir + f\"{atom_name_list[atom]}_sigx_unit_cell_{sample}.txt\", atom_resolved_params[atom][1, :])\n",
    "    np.savetxt(base_dir + f\"{atom_name_list[atom]}_sigy_unit_cell_{sample}.txt\", atom_resolved_params[atom][2, :])\n",
    "    np.savetxt(base_dir + f\"{atom_name_list[atom]}_theta_unit_cell_{sample}.txt\", atom_resolved_params[atom][3, :])\n",
    "\n",
    "uc_result_dic = {}\n",
    "\n",
    "for atom in range(len(atom_num_list)):\n",
    "\n",
    "    uc_result_dic[atom_name_list[atom]+\"_x\"] = atom_resolved_positions[atom][0, :]\n",
    "    uc_result_dic[atom_name_list[atom]+\"_y\"] = atom_resolved_positions[atom][1, :]\n",
    "    uc_result_dic[atom_name_list[atom]+\"_A\"] = atom_resolved_params[atom][0, :]\n",
    "    uc_result_dic[atom_name_list[atom]+\"_sigx\"] = atom_resolved_params[atom][1, :]\n",
    "    uc_result_dic[atom_name_list[atom]+\"_singy\"] = atom_resolved_params[atom][2, :]\n",
    "    uc_result_dic[atom_name_list[atom]+\"_theta\"] = atom_resolved_params[atom][3, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc12fed-f4c0-4282-ad18-4f7414ce6754",
   "metadata": {},
   "source": [
    "## Position generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf348e06-479d-4a5d-9a41-a6d3981ccc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code to see that the positions are well generated.\n",
    "\n",
    "# positions is an array with the shape of (2, n), where 2 is for x and y cordinates and n is the number of total atoms analyzed.\n",
    "# atom_resolved_positions is a list whose elements are the positions of each atom type.\n",
    "\n",
    "positions_file_name = \"positions\"\n",
    "\n",
    "positions, params = tools.positions_params_gen(lattices, posit_pix_peaks, tfv_dposit, \n",
    "                                               tfv_unit_cell_params, lattice_num, atom_num_list)\n",
    "atom_resolved_positions = tools.unpack_atom_type(positions,  lattice_num,  atom_num_list)\n",
    "# list of positions, where each list elements the positions of each atom species\n",
    "\n",
    "plt.imshow(im_analyzed, cmap = \"gray\")\n",
    "plt.title(\"Positions look vaild?\")\n",
    "\n",
    "for atom in range(len(atom_num_list)):\n",
    "    \n",
    "    plt.scatter(atom_resolved_positions[atom][0,:], atom_resolved_positions[atom][1,:], s = 1)\n",
    "\n",
    "np.save(base_dir + positions_file_name + \"_\" + sample, positions) \n",
    "\n",
    "simulated_image = gf.Gaussian_np_fine(positions, np.zeros(positions.shape), \n",
    "                                        params, atom_num_list, \n",
    "                                        pad_size_list, im_shape)\n",
    "\n",
    "print(\"loss from positions:\", lf.compute_loss_np(im_analyzed, simulated_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab49a0f-b6e8-44b9-af9d-b775372107bf",
   "metadata": {},
   "source": [
    "## Lattice corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b93dd0-d4ff-4631-a5b9-0382f8449f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_atom = [0, 0]    # atom, indice of atom in posit_pix\n",
    "anchor_atom_pad = 10\n",
    "\n",
    "marker_size = 1\n",
    "\n",
    "positions_c, lattices_c = tools.positions_correction(positions, posit_pix_peaks, \n",
    "                                               lattices, anchor_atom, anchor_atom_pad,\n",
    "                                                     atom_num_list, lattice_num, \n",
    "                                               im_analyzed, marker_size, row, col, \n",
    "                                                    tfv_dposit)\n",
    "\n",
    "atom_resolved_positions = tools.unpack_atom_type(positions_c, lattice_num, \n",
    "                                                 atom_num_list)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(im_analyzed, cmap = \"gray\")\n",
    "plt.title(\"Positions look vaild?\")\n",
    "\n",
    "for atom in range(len(atom_num_list)):\n",
    "    \n",
    "    plt.scatter(atom_resolved_positions[atom][0,:], atom_resolved_positions[atom][1,:], s = marker_size)\n",
    "\n",
    "simulated_image = gf.Gaussian_np_fine(positions_c, np.zeros(positions.shape), \n",
    "                                        params, atom_num_list, \n",
    "                                        pad_size_list, im_shape)\n",
    "\n",
    "print(\"loss from corrected positiions:\", lf.compute_loss_np(im_analyzed, simulated_image))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a56c05-07e0-4444-867f-e6f50486fd53",
   "metadata": {},
   "source": [
    "## Position correction with peak finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bfbc12-5178-4bb3-9677-136eb0f062ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_peak_file_name = \"positions_peak\"\n",
    "\n",
    "peak_finder_pad_size_list = [5, 5, 5]\n",
    "marker_size = 5\n",
    "\n",
    "\n",
    "positions_peak = tools.positions_peak_finder(positions_c, \n",
    "                                                  atom_num_list, \n",
    "                                                  lattice_num, \n",
    "                                                         peak_finder_pad_size_list,\n",
    "                                                        im_analyzed, atom_name_list)\n",
    "\n",
    "atom_resolved_positions = tools.unpack_atom_type(positions_peak,  \n",
    "                                                 lattice_num,  atom_num_list)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(im_analyzed, cmap = \"gray\")\n",
    "plt.title(\"Positions look vaild?\")\n",
    "\n",
    "for atom in range(len(atom_num_list)):\n",
    "    \n",
    "    plt.scatter(atom_resolved_positions[atom][0,:], atom_resolved_positions[atom][1,:], \n",
    "                s = marker_size)\n",
    "\n",
    "\n",
    "tfv_dpositions = tf.Variable(tf.zeros((2, positions_peak.shape[1]), \n",
    "                                      dtype = tf.float32))\n",
    "tfv_params = tf.Variable(tf.cast(params, dtype = tf.float32))\n",
    "\n",
    "loss_array = []\n",
    "\n",
    "np.save(base_dir + positions_peak_file_name + \"_\" + sample, positions_peak) \n",
    "\n",
    "simulated_image = gf.Gaussian_np_fine(positions_peak, np.zeros(positions.shape), \n",
    "                                        params, atom_num_list, \n",
    "                                        pad_size_list, im_shape)\n",
    "\n",
    "print(\"\\nloss from corrected positiions_peak:\", lf.compute_loss_np(im_analyzed, simulated_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee952112-d9bf-4755-920a-b4e4efa56259",
   "metadata": {},
   "source": [
    "## Free atom optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6aa333-821d-4cd9-a80c-773ce2bc5c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpositions_file_name = \"dpositions\"         # Optimized positions\n",
    "params_file_name = \"params\"                 # Optimized Gaussain parameters\n",
    "loss_file_name = \"loss\"\n",
    "\n",
    "n_iter = 500\n",
    "\n",
    "lr_pos = 1e-3\n",
    "lr_param = 1e-2\n",
    "\n",
    "print_num = 10\n",
    "\n",
    "Fixed_params = [[1, 1], [2, 2]]     \n",
    "\n",
    "mask_params = tools.free_atom_mask(lattice_num, atom_num_list, Fixed_params)\n",
    "# Gradient mask for fixed parameters\n",
    "\n",
    "Max_position_modul = 0.5\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "\n",
    "tfv_dpositions.assign(tf.clip_by_value(tfv_dpositions, -Max_position_modul, Max_position_modul))\n",
    "\n",
    "im_shape = im_analyzed.shape\n",
    "\n",
    "pos_optimizer = tf.optimizers.Adam(learning_rate=lr_pos) \n",
    "param_optimizer = tf.optimizers.Adam(learning_rate=lr_param)\n",
    "variables = [tfv_dpositions, tfv_params]\n",
    "\n",
    "for i in range(n_iter):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        simulated_image = gf.Gaussian_fine(positions_peak, tfv_dpositions, \n",
    "                                        tfv_params, atom_num_list, \n",
    "                                        pad_size_list, im_shape)\n",
    "\n",
    "        loss = lf.compute_loss_tf(tf_im_analyzed, simulated_image)\n",
    "        loss_array.append(loss)\n",
    "\n",
    "        grads = tape.gradient(loss, variables) \n",
    "\n",
    "        if len(Fixed_params) != 0:\n",
    "\n",
    "            grads[1] = tf.tensor_scatter_nd_update(grads[1], mask_params, \n",
    "                                                   tf.zeros([len(mask_params),]))\n",
    "        \n",
    "        pos_optimizer.apply_gradients([(grads[0], tfv_dpositions)])\n",
    "        param_optimizer.apply_gradients([(grads[1], tfv_params)])\n",
    "        \n",
    "        np.save(base_dir + params_file_name + \"_\" + sample, np.array(tfv_params)) \n",
    "        np.save(base_dir + dpositions_file_name + \"_\" + sample, np.array(tfv_dpositions)) \n",
    "\n",
    "        if i % print_num == 0:\n",
    "            \n",
    "            print(f'{i}, current_loss: {loss}')\n",
    "     \n",
    "plt.plot(np.arange(len(loss_array)), loss_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e053d49-e7aa-4978-9fe4-c853bfa29731",
   "metadata": {},
   "source": [
    "## Free atom optimization results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5222e10-c69d-4e6e-bf20-c55366c4e8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code to see the change in the lattice information and compare the TEM image and fitted image\n",
    "\n",
    "# laod positions and params\n",
    "dpositions_file_name = \"dpositions\"        # Optimized positions\n",
    "params_file_name = \"params\"              # Optimized Gaussain parameters\n",
    "\n",
    "marker_size = 5\n",
    "\n",
    "positions_peak_file_name = \"positions_peak\"\n",
    "lattice_num_file_name = \"lattice_num\"\n",
    "atom_num_list_file_name = \"atom_num_list\"\n",
    "pad_size_list_file_name = \"pad_size_list\"\n",
    "im_analyzed_file_name = \"im_analyzed\"\n",
    "atom_name_list_file_name = \"atom_name_list\"\n",
    "\n",
    "np.save(base_dir + first_posit_pix_file_name + \"_\" + sample, posit_pix_peaks[0][0])\n",
    "\n",
    "\n",
    "# positions and parameters are the arrays of optimized positions and Gaussian parameters with the shape of (2, n).\n",
    "# tfv_params is the variable version of params.\n",
    "# atom_resolved_positions is a list with the length of number of atom type, whose elements are the optmized positions of each atom type.\n",
    "\n",
    "im_analyzed = np.load(base_dir + im_analyzed_file_name + \"_\" + sample + \".npy\")\n",
    "positions_peak = np.load(base_dir + positions_peak_file_name + \"_\" + sample + \".npy\")\n",
    "lattice_num = np.load(base_dir + lattice_num_file_name + \"_\" + sample + \".npy\")\n",
    "atom_num_list = np.load(base_dir + atom_num_list_file_name + \"_\" + sample + \".npy\")\n",
    "pad_size_list = np.load(base_dir + pad_size_list_file_name + \"_\" + sample + \".npy\")\n",
    "atom_name_list = np.load(base_dir + atom_name_list_file_name + \"_\" + sample + \".npy\")\n",
    "\n",
    "tf_im_analyzed = tf.cast(im_analyzed, dtype = tf.float32)\n",
    "\n",
    "loss_array = []\n",
    "\n",
    "tfv_params, tfv_dpositions, atom_resolved_positions, atom_resolved_params = \\\n",
    "tools.free_atom_opmization_results(base_dir, dpositions_file_name, params_file_name,\n",
    "                                      positions_peak, lattice_num, atom_num_list, pad_size_list, \n",
    "                                      im_analyzed, marker_size, sample)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbef6bed-173e-42b1-bcf6-8a1606c30dab",
   "metadata": {},
   "source": [
    "## Cutting boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc32c028-1c64-4beb-85a3-fbb97a37081c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cutting boundaries. cut_col = 1 for cutting right and left most columns, and cut_row = 1 for cutting\n",
    "# top and bottom rows.\n",
    "\n",
    "cut_col = 1\n",
    "cut_row = 0        \n",
    "\n",
    "marker_size = 5\n",
    "\n",
    "cut_atom_positions_file_name = \"cut_atom_positions\"\n",
    "cut_atom_params_file_name = \"cut_atom_params\"\n",
    "\n",
    "x_lattice_file_name = \"x_lattice\"\n",
    "y_lattice_file_name = \"y_lattice\"\n",
    "len_pix_file_name = \"len_pix\"\n",
    "\n",
    "x_lattice = np.load(base_dir + x_lattice_file_name + \"_\" + sample + \".npy\")\n",
    "y_lattice = np.load(base_dir + y_lattice_file_name + \"_\" + sample + \".npy\")\n",
    "len_pix = np.load(base_dir + len_pix_file_name + \"_\" + sample + \".npy\")\n",
    "\n",
    "# Operation code -----------------------------------------------------------------------------------------------\n",
    "\n",
    "# cut_atom_positions and cut_atom_params is the cut versions of positions and params.\n",
    "\n",
    "cut_atom_positions, cut_atom_params = tools.boundary_cut(atom_resolved_positions, \n",
    "                                                         atom_resolved_params, \n",
    "                                                         row, col, cut_col = cut_col, \n",
    "                                                         cut_row = cut_row)\n",
    "\n",
    "row_cut_start = int(y*cut_row/len_pix)\n",
    "row_cut_end = im_analyzed.shape[0]-int(y*cut_row/len_pix)\n",
    "col_cut_start = int(x*cut_col/len_pix)\n",
    "col_cut_end = im_analyzed.shape[1]-int(x*cut_col/len_pix)\n",
    "\n",
    "plt.imshow(im_analyzed[row_cut_start:row_cut_end, \n",
    "             col_cut_start : col_cut_end], cmap = \"gray\")\n",
    "plt.title(\"TEM image with markers\")\n",
    "\n",
    "for atom in range(len(atom_num_list)):\n",
    "    \n",
    "    plt.scatter(cut_atom_positions[atom][0,:] - col_cut_start, \n",
    "                cut_atom_positions[atom][1,:]-row_cut_start, \n",
    "                s = marker_size, label = atom_name_list[atom])\n",
    "\n",
    "plt.legend(loc = \"lower left\",\n",
    "              bbox_to_anchor = (1.02, 0),\n",
    "              frameon=False)\n",
    "plt.savefig(base_dir + f\"TEM image with markers_{sample}.png\", \n",
    "            bbox_inches = \"tight\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize = (10, 5))\n",
    "\n",
    "ax[0].imshow(im_analyzed[row_cut_start:row_cut_end, \n",
    "             col_cut_start : col_cut_end], cmap = \"gray\")\n",
    "ax[0].set_title(\"TEM image\")\n",
    "ax[1].imshow(gf.Gaussian_np_fine(positions_peak, tfv_dpositions, tfv_params, \n",
    "                                 atom_num_list, pad_size_list, im_analyzed.shape)[row_cut_start:row_cut_end, \n",
    "             col_cut_start : col_cut_end], cmap = \"gray\")\n",
    "ax[1].set_title(\"Simulated TEM image\")\n",
    "\n",
    "cut_image = im_analyzed[row_cut_start:row_cut_end, col_cut_start : col_cut_end]\n",
    "cut_simul = gf.Gaussian_np_fine(positions_peak, tfv_dpositions, tfv_params, \n",
    "                                atom_num_list, pad_size_list, im_analyzed.shape)[row_cut_start:row_cut_end, \n",
    "             col_cut_start : col_cut_end]\n",
    "\n",
    "plt.savefig(base_dir + f\"TEM image and fitted image_{sample}.png\", bbox_inches = \"tight\")\n",
    "np.savetxt(base_dir + f\"TEM image for markers_{sample}.png\", cut_image)\n",
    "\n",
    "\n",
    "obj_positions = np.empty(len(cut_atom_positions), dtype=object)\n",
    "for i, v in enumerate(cut_atom_positions):\n",
    "    obj_positions[i] = np.array(v, copy=True)\n",
    "\n",
    "obj_params = np.empty(len(cut_atom_params), dtype=object)\n",
    "for i, v in enumerate(cut_atom_params):\n",
    "    obj_params[i] = np.array(v, copy=True)\n",
    "\n",
    "np.save(base_dir + cut_atom_positions_file_name + \"_\" + sample,\n",
    "       obj_positions, allow_pickle=True)\n",
    "\n",
    "np.save(base_dir + cut_atom_params_file_name + \"_\" + sample,\n",
    "       obj_params, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a8eafd-70d1-41c6-a0d5-77cb9dc5a561",
   "metadata": {},
   "source": [
    "## Dictionary generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4412495a-bb5b-4bad-a4d8-cff9aa2ce0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_atom_positions_file_name = \"cut_atom_positions\"\n",
    "cut_atom_params_file_name = \"cut_atom_params\"\n",
    "first_posit_pix_file_name = \"first_posit_pix\"\n",
    "unitcell_file_name = \"unitcell\"\n",
    "atom_num_list_file_name = \"atom_num_list\"\n",
    "pad_size_list_file_name = \"pad_size_list\"\n",
    "atom_name_list_file_name = \"atom_name_list\"\n",
    "\n",
    "obj_positions = np.load(base_dir + cut_atom_positions_file_name +\\\n",
    "                        \"_\" + sample + \".npy\", allow_pickle=True)\n",
    "cut_atom_positions = obj_positions.tolist()  \n",
    "\n",
    "obj_params = np.load(base_dir + cut_atom_params_file_name +\\\n",
    "                        \"_\" + sample + \".npy\", allow_pickle=True)\n",
    "cut_atom_params = obj_params.tolist()  \n",
    "\n",
    "first_posit_pix = np.load(base_dir + first_posit_pix_file_name + \"_\" + sample + \".npy\")\n",
    "unit_cell_image = np.load(base_dir + unitcell_file_name + \"_\" + sample + \".npy\")\n",
    "atom_num_list = np.load(base_dir + atom_num_list_file_name + \"_\" + sample + \".npy\")\n",
    "pad_size_list = np.load(base_dir + pad_size_list_file_name + \"_\" + sample + \".npy\")\n",
    "atom_name_list = np.load(base_dir + atom_name_list_file_name + \"_\" + sample + \".npy\")\n",
    "\n",
    "dictionary = {}\n",
    "\n",
    "dictionary[\"posit_pix_optimized\"] = []\n",
    "dictionary[\"unit_cell_params_optimized\"] = []\n",
    "\n",
    "for atom in range(len(atom_num_list)):\n",
    "\n",
    "    dictionary[atom_name_list[atom] + \"_pos\"] = cut_atom_positions[atom]\n",
    "    dictionary[atom_name_list[atom] + \"_par\"] = cut_atom_params[atom]\n",
    "\n",
    "    dictionary[atom_name_list[atom] + \"_pos_avg\"] = np.mean(dictionary[atom_name_list[atom] + \"_pos\"], axis = 1)\n",
    "    dictionary[atom_name_list[atom] + \"_par_avg\"] = np.mean(dictionary[atom_name_list[atom] + \"_par\"], axis = 1)\n",
    "\n",
    "    dictionary[atom_name_list[atom] + \"_pos_std\"] = np.std(dictionary[atom_name_list[atom] + \"_pos\"], axis = 1)\n",
    "    dictionary[atom_name_list[atom] + \"_par_std\"] = np.std(dictionary[atom_name_list[atom] + \"_par\"], axis = 1)\n",
    "\n",
    "    positions_aligned = \\\n",
    "    cut_atom_positions[atom].reshape(2, -1, atom_num_list[atom])\n",
    "\n",
    "    params_aligned = \\\n",
    "    cut_atom_params[atom].reshape(4, -1, atom_num_list[atom])\n",
    "\n",
    "    dictionary[atom_name_list[atom] + \"_uc_pos\"] =\\\n",
    "    np.mean(positions_aligned,\n",
    "           axis = 2)\n",
    "\n",
    "    dictionary[atom_name_list[atom] + \"_uc_par\"] =\\\n",
    "    np.mean(params_aligned,\n",
    "           axis = 2)\n",
    "\n",
    "    for order in range(atom_num_list[atom]):\n",
    "\n",
    "        dictionary[atom_name_list[atom]+ f\"_{order}\" + \"_pos\"] = positions_aligned[:, :, order]\n",
    "        dictionary[atom_name_list[atom]+ f\"_{order}\" + \"_par\"] = params_aligned[:, :, order]\n",
    "\n",
    "        dictionary[atom_name_list[atom]+ f\"_{order}\" + \"_pos_avg\"] = np.mean(dictionary[atom_name_list[atom]+ f\"_{order}\" + \"_pos\"], axis = 1)\n",
    "        dictionary[atom_name_list[atom]+ f\"_{order}\" + \"_par_avg\"] = np.mean(dictionary[atom_name_list[atom]+ f\"_{order}\" + \"_par\"], axis = 1)\n",
    "\n",
    "        dictionary[atom_name_list[atom]+ f\"_{order}\" + \"_pos_std\"] = np.std(dictionary[atom_name_list[atom]+ f\"_{order}\" + \"_pos\"], axis = 1)\n",
    "        dictionary[atom_name_list[atom]+ f\"_{order}\" + \"_par_std\"] = np.std(dictionary[atom_name_list[atom]+ f\"_{order}\" + \"_par\"], axis = 1)\n",
    "\n",
    "for atom in range(len(atom_num_list)):\n",
    "\n",
    "    np.savetxt(base_dir + atom_name_list[atom] + \"_pos\" + \"_\" + sample, \n",
    "               dictionary[atom_name_list[atom] + \"_pos\"])\n",
    "\n",
    "    np.savetxt(base_dir + atom_name_list[atom] + \"_par\" + \"_\" + sample, \n",
    "               dictionary[atom_name_list[atom] + \"_par\"])\n",
    "\n",
    "    np.savetxt(base_dir + atom_name_list[atom] + \"_pos_avg\" + \"_\" + sample, \n",
    "               dictionary[atom_name_list[atom] + \"_pos_avg\"])\n",
    "\n",
    "    np.savetxt(base_dir + atom_name_list[atom] + \"_par_avg\" + \"_\" + sample, \n",
    "               dictionary[atom_name_list[atom] + \"_par_avg\"])\n",
    "\n",
    "    np.savetxt(base_dir + atom_name_list[atom] + \"_pos_std\" + \"_\" + sample, \n",
    "               dictionary[atom_name_list[atom] + \"_pos_std\"])\n",
    "\n",
    "    np.savetxt(base_dir + atom_name_list[atom] + \"_par_std\" + \"_\" + sample, \n",
    "               dictionary[atom_name_list[atom] + \"_par_std\"])# atom_par_avg(std) : Gaussian paramters of the atom\n",
    "\n",
    "    np.savetxt(base_dir + atom_name_list[atom] + \"_uc_pos\" + \"_\" + sample, \n",
    "               dictionary[atom_name_list[atom] + \"_uc_pos\"])\n",
    "\n",
    "    np.savetxt(base_dir + atom_name_list[atom] + \"_uc_par\" + \"_\" + sample, \n",
    "               dictionary[atom_name_list[atom] + \"_uc_par\"])\n",
    "\n",
    "    for order in range(atom_num_list[atom]):\n",
    "\n",
    "        np.savetxt(base_dir + atom_name_list[atom]+ f\"_{order}\" + \"_pos\" + \"_\" + sample, \n",
    "           dictionary[atom_name_list[atom]+ f\"_{order}\" + \"_pos\"])\n",
    "        np.savetxt(base_dir + atom_name_list[atom]+ f\"_{order}\" + \"_par\" + \"_\" + sample, \n",
    "           dictionary[atom_name_list[atom]+ f\"_{order}\" + \"_par\"])\n",
    "        \n",
    "        np.savetxt(base_dir + atom_name_list[atom]+ f\"_{order}\" + \"_pos_avg\" + \"_\" + sample, \n",
    "           dictionary[atom_name_list[atom]+ f\"_{order}\" + \"_pos_avg\"])\n",
    "        np.savetxt(base_dir + atom_name_list[atom]+ f\"_{order}\" + \"_par_avg\" + \"_\" + sample, \n",
    "           dictionary[atom_name_list[atom]+ f\"_{order}\" + \"_par_avg\"])\n",
    "        \n",
    "        np.savetxt(base_dir + atom_name_list[atom]+ f\"_{order}\" + \"_pos_std\" + \"_\" + sample, \n",
    "           dictionary[atom_name_list[atom]+ f\"_{order}\" + \"_pos_std\"])\n",
    "        np.savetxt(base_dir + atom_name_list[atom]+ f\"_{order}\" + \"_par_std\" + \"_\" + sample, \n",
    "           dictionary[atom_name_list[atom]+ f\"_{order}\" + \"_par_std\"])\n",
    "\n",
    "\n",
    "# atom_pos(par) : positions (Gaussian parameters) of the atom\n",
    "\n",
    "# atom_pos(par)_avg(std) : average(standard deviation) of atom_pos(par)\n",
    "\n",
    "# atom_uc_pos(par) : unit cell average positions(Gaussian parameters) of the atom\n",
    "\n",
    "# atom_n_pos(par) : positions(Gaussain parameters) of the atom at n'th position in the unit cell\n",
    "\n",
    "# atom_n_pos(par)_avg(std) : average(standard deviation) of atom_pos(par) of atom_n_pos(par)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
